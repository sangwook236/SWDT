[-] General.
	- Site.
		https://developer.nvidia.com/cuda-zone

		https://code.google.com/p/cudpp/

	- Documentation.
		https://docs.nvidia.com/cuda/
		https://docs.nvidia.com/cuda/cuda-c-programming-guide/

		https://docs.nvidia.com/cuda/cuda-runtime-api/
		https://docs.nvidia.com/cuda/cuda-driver-api/
		https://docs.nvidia.com/cuda/cuda-math-api/
		https://docs.nvidia.com/cuda/cublas/
		https://docs.nvidia.com/cuda/cufft/
		https://docs.nvidia.com/cuda/curand/
		https://docs.nvidia.com/cuda/cusparse/
		https://docs.nvidia.com/cuda/cusolver/
		https://nvidia.github.io/cccl/cub/
		https://nvidia.github.io/cccl/libcudacxx/
		https://nvidia.github.io/cccl/thrust/

		https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/
		https://docs.nvidia.com/nsight-compute/
		https://docs.nvidia.com/nsight-visual-studio-edition/
		https://docs.nvidia.com/cuda/profiler-users-guide/

	- Tutorial.
		http://www.vizworld.com/2009/06/isc-2009-cuda-tutorial-from-nvidia/

	- Directory.
		/usr/local/cuda/targets/x86_64-linux/include
		/usr/local/cuda/targets/x86_64-linux/lib

[-] Usage.
	- CUDA toolkit version.
		Install CUDA toolkit. (Ubuntu)
			sudo apt install nvidia-cuda-toolkit

		nvcc --version
			/usr/local/cuda/bin/nvcc --version
		cat /usr/local/cuda/version.txt (X)
		cat /usr/local/cuda/include/cuda.h
			Find CUDA_VERSION.

		Runtime API version:
			cudaRuntimeGetVersion()
		Driver API version:
			cudaDriverGetVersion()
			cuDriverGetVersion()

		cudatoolkit version (Python):
			conda list
				cudatoolkit
				pytorch-cuda

	- Driver version.
		Install driver. (Ubuntu)
			(Optional) sudo add-apt-repository ppa:graphics-drivers/ppa

			ubuntu-drivers devices

			sudo ubuntu-drivers autoinstall
				Alternatively,
					sudo apt install nvidia-driver-525
					sudo apt install nvidia-utils-525
						For nvidia-smi.

			sudo reboot

		cat /proc/driver/nvidia/version
		nvidia-smi

		lspci -v
			lspci -v | grep NVIDIA

	- cuDNN version.
		cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
		cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2
		cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2

	- Architecture.
		https://developer.nvidia.com/cuda-gpus

		GPU						Compute Capability 		Streaming Multiprocessor
		GeForce RTX 3090 Ti		8.6	(compute_86)		sm_86
		GeForce GTX 1080 Ti		6.1	(compute_61)		sm_61

			compute_XX: architecture for a virtual (intermediate) code representation.
			sm_XX: architecture for the real representation.

		nvidia-smi --query-gpu=compute_cap --format=csv
		GPU-Z.

	- Docker.
		Refer to docker_usage_guide.txt & triton_usage_guide.txt.

[-] Usage (NVIDIA System Management Interface, nvidia-smi).
	https://www.microway.com/hpc-tech-tips/nvidia-smi_control-your-gpus/
	https://developer.nvidia.com/nvidia-system-management-interface

	- Monitoring.
		watch -n 0.5 nvidia-smi

	- Querying GPU Status.
		List all available NVIDIA devices:
			nvidia-smi -L
		List certain details about each GPU:
			nvidia-smi --query-gpu=index,name,uuid,serial --format=csv

		Monitor overall GPU usage with 1-second update intervals:
			nvidia-smi dmon
		Monitor per-process GPU usage with 1-second update intervals:
			nvidia-smi pmon

		List available clock speeds for each GPU:
			nvidia-smi -q -d SUPPORTED_CLOCKS
		Review the current GPU clock speed, default clock speed, and maximum possible clock speed:
			nvidia-smi -q -d CLOCK
		Review the current state of each GPU and any reasons for clock slowdowns:
			nvidia-smi -q -d PERFORMANCE

	- Tuning.
		Set persistence mode:
			nvidia-smi -pm 1
				0: DISABLED, 1: ENABLED.

			Persistence Mode:
				On Linux, you can set GPUs to persistence mode to keep the NVIDIA driver loaded even when no applications are accessing the cards.
				This is particularly useful when you have a series of short jobs running.
				Persistence mode uses a few more watts per idle GPU, but prevents the fairly long delays that occur each time a GPU application is started.
				It is also necessary if you've assigned specific clock speeds or power limits to the GPUs (as those changes are lost when the NVIDIA driver is unloaded).
				On Windows, nvidia-smi is not able to set persistence mode.
				Instead, you need to set your computational GPUs to TCC mode.
				This should be done through NVIDIA's graphical GPU device management panel.

		Toggles permission requirements for -ac and -rac commands:
			nvidia-smi -acp 0
				0: UNRESTRICTED, 1: RESTRICTED.

		Set max. memory and graphic clocks:
			nvidia-smi -ac "877,1380"
				Run "nvidia-smi -q -d CLOCK" to see max. memory and graphic clocks.

[-] Usage (TensorRT, TRTorch, TF-TRT).
	Refer to ./tensorrt_usage_guide.txt

[-] Installation.
	- Log.
		/var/log/cuda-installer.log

	- Install driver.
		sudo ubuntu-drivers devices
		sudo ubuntu-drivers autoinstall

		sudo apt install nvidia-driver-455

		sudo <CudaInstaller>.run --driver --silent
			e.g.) sudo sh cuda_11.1.0_455.23.05_linux.run --driver --silent

	- Install CUDA toolkit.
		sudo apt install nvidia-cuda-toolkit

		sudo <CudaInstaller>.run
			e.g.) sudo sh cuda_11.1.0_455.23.05_linux.run --toolkit --silent

	- Uninstall.
		cd ${CUDA_HOME}/bin
		cuda-uninstaller

[-] Troubleshooting.
	- <error> RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR.
		<cause> The version of cudatoolkit is unmatched. (?)
		<solution> conda install cudatoolkit=10.1.xxx (?)
